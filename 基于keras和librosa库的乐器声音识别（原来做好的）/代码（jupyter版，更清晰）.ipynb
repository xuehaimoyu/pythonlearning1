{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db30a336",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.models import load_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.utils import np_utils\n",
    "from keras import models\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential   # 网络模型\n",
    "from keras.layers import Dense,Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fc1d2f",
   "metadata": {},
   "source": [
    "# python librosa库有时会出现bug，现实backend error，此时需要打开ffmpeg包，添加到环境变量，然后在librosa下的aread.py里打开,然后将ffmpeg.py的路径替换。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00418e70",
   "metadata": {},
   "source": [
    "# 将训练数据先进行预处理，对每个曲目进行频谱分析，将各个特征的结果保存在array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69cb274f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'piano': 0, 'guitar': 1, 'violin': 2, 'changdi': 3, 'shoufengqin': 4}\n",
      "piano\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cm\\anaconda3\\lib\\site-packages\\librosa\\core\\audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "C:\\Users\\cm\\anaconda3\\lib\\site-packages\\librosa\\core\\audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "guitar\n",
      "violin\n",
      "changdi\n",
      "shoufengqin\n"
     ]
    }
   ],
   "source": [
    "classes = 'piano guitar violin changdi shoufengqin'.split()\n",
    "data_set = []\n",
    "label_set = [] \n",
    "label2id = {class1:i for i,class1 in enumerate(classes)}\n",
    "id2label = {i:class1 for i,class1 in enumerate(classes)}\n",
    "print(label2id)\n",
    "for c in classes:\n",
    "    print(c)\n",
    "    for filename in os.listdir(f'D:/张斯然文件/musicdate/date/classes/{c}/'):\n",
    "        songname = f'D:/张斯然文件/musicdate/date/classes/{c}/{filename}'\n",
    "        y, sr = librosa.load(songname, mono=True, duration=30)\n",
    "        chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "        rmse = librosa.feature.rms(y=y)\n",
    "        spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "        spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "        rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "        zcr = librosa.feature.zero_crossing_rate(y)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    " \n",
    "        to_append = f'{np.mean(chroma_stft)} {np.mean(rmse)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'     \n",
    "        for e in mfcc:\n",
    "            to_append += f' {np.mean(e)}' \n",
    "        data_set.append([float(i) for i in to_append.split(\" \")])\n",
    "        label_set.append(label2id[c])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f082bf2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(np.array(data_set, dtype = float))\n",
    "y = np_utils.to_categorical(np.array(label_set))\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "print(X_train.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb087ce",
   "metadata": {},
   "source": [
    "# 准备模型的建立"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be070f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model_creat():\n",
    "    model= Sequential()\n",
    "    model.add(Dense(units=120,activation='relu',input_shape=(X_train.shape[1],)))#构建两个层\n",
    "    model.add(Dense(units=60,activation='relu'))\n",
    "    model.add(Dense(units=30, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(units=5,activation='softmax'))#输出节点\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b972f58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Model_creat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afe30be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy','categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c13f177",
   "metadata": {},
   "source": [
    "### 模型的训练过程还是出现过许多问题，有时候在最后一层使用relu，使得loss不能成功计算，通过不停的调整参数和进行比较，得到比较好的结果有model13,modelshow,均已经保存在savemodel里了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63cbacde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2/2 [==============================] - 17s 3ms/step - loss: 1.7172 - accuracy: 0.1721 - categorical_accuracy: 0.1721\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.5585 - accuracy: 0.2248 - categorical_accuracy: 0.2248\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.4352 - accuracy: 0.2900 - categorical_accuracy: 0.2900\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.3507 - accuracy: 0.3613 - categorical_accuracy: 0.3613\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.2508 - accuracy: 0.4021 - categorical_accuracy: 0.4021\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.1750 - accuracy: 0.5319 - categorical_accuracy: 0.5319\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.1046 - accuracy: 0.6031 - categorical_accuracy: 0.6031\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.1132 - accuracy: 0.6231 - categorical_accuracy: 0.6231\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.0094 - accuracy: 0.7410 - categorical_accuracy: 0.7410\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.9927 - accuracy: 0.6750 - categorical_accuracy: 0.6750\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.9153 - accuracy: 0.7500 - categorical_accuracy: 0.7500\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.8732 - accuracy: 0.7315 - categorical_accuracy: 0.7315\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.7834 - accuracy: 0.7581 - categorical_accuracy: 0.7581\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.8340 - accuracy: 0.6194 - categorical_accuracy: 0.6194\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.7833 - accuracy: 0.6654 - categorical_accuracy: 0.6654\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6698 - accuracy: 0.7871 - categorical_accuracy: 0.7871\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5482 - accuracy: 0.8635 - categorical_accuracy: 0.8635\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5670 - accuracy: 0.7990 - categorical_accuracy: 0.7990\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5580 - accuracy: 0.8227 - categorical_accuracy: 0.8227\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5233 - accuracy: 0.8531 - categorical_accuracy: 0.8531\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.8398 - categorical_accuracy: 0.8398\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5197 - accuracy: 0.8294 - categorical_accuracy: 0.8294\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5246 - accuracy: 0.7990 - categorical_accuracy: 0.7990\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4198 - accuracy: 0.8583 - categorical_accuracy: 0.8583\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.3621 - accuracy: 0.8917 - categorical_accuracy: 0.8917\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3034 - accuracy: 0.9140 - categorical_accuracy: 0.9140\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3397 - accuracy: 0.8798 - categorical_accuracy: 0.8798\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.2810 - accuracy: 0.9392 - categorical_accuracy: 0.9392\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3446 - accuracy: 0.9035 - categorical_accuracy: 0.9035\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2491 - accuracy: 0.9273 - categorical_accuracy: 0.9273\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2080 - accuracy: 0.9458 - categorical_accuracy: 0.9458\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1663 - accuracy: 0.9681 - categorical_accuracy: 0.9681\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3205 - accuracy: 0.8494 - categorical_accuracy: 0.8494\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2212 - accuracy: 0.9458 - categorical_accuracy: 0.9458\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2342 - accuracy: 0.9287 - categorical_accuracy: 0.9287\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1529 - accuracy: 0.9681 - categorical_accuracy: 0.9681\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2097 - accuracy: 0.9310 - categorical_accuracy: 0.9310\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2377 - accuracy: 0.9392 - categorical_accuracy: 0.9392\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1451 - accuracy: 0.9615 - categorical_accuracy: 0.9615\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1643 - accuracy: 0.9681 - categorical_accuracy: 0.9681\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1477 - accuracy: 0.9577 - categorical_accuracy: 0.9577\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1530 - accuracy: 0.9392 - categorical_accuracy: 0.9392\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1980 - accuracy: 0.9206 - categorical_accuracy: 0.9206\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1347 - accuracy: 0.9444 - categorical_accuracy: 0.9444\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1469 - accuracy: 0.9644 - categorical_accuracy: 0.9644\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0998 - accuracy: 0.9815 - categorical_accuracy: 0.9815\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 999us/step - loss: 0.0923 - accuracy: 0.9696 - categorical_accuracy: 0.9696\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1480 - accuracy: 0.9340 - categorical_accuracy: 0.9340\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1056 - accuracy: 0.9562 - categorical_accuracy: 0.9562\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1218 - accuracy: 0.9644 - categorical_accuracy: 0.9644\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2761b1287c0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=50, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1139dc1b",
   "metadata": {},
   "source": [
    "# 保存训练好的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f504a4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#model.save(f'D:/张斯然文件/musicdate/date/modelshow.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f308a71a",
   "metadata": {},
   "source": [
    "# 尝试进行验证，选了训练集中没有的5个曲目，保存在数据集目录下classes下的test类里，结果发现还挺准的，但是看概率的话，有一两个可能有点模糊\n",
    "\n",
    "c——长笛\n",
    "\n",
    "g——吉他\n",
    "\n",
    "s——手风琴\n",
    "\n",
    "p——钢琴\n",
    "\n",
    "v——小提琴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9da94f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/张斯然文件/musicdate/date/classes/test/c1.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cm\\anaconda3\\lib\\site-packages\\librosa\\core\\audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/张斯然文件/musicdate/date/classes/test/g1.mp3\n",
      "D:/张斯然文件/musicdate/date/classes/test/p1.mp3\n",
      "D:/张斯然文件/musicdate/date/classes/test/s1.mp3\n",
      "D:/张斯然文件/musicdate/date/classes/test/v1.mp3\n",
      "[[1.84158352e-03 1.42207171e-03 1.31978682e-04 9.96122897e-01\n",
      "  4.81391791e-04]\n",
      " [2.12312430e-01 7.36021459e-01 5.59710013e-03 1.47150655e-03\n",
      "  4.45974581e-02]\n",
      " [8.45506310e-01 1.22267537e-01 5.69243683e-03 1.21670775e-02\n",
      "  1.43666435e-02]\n",
      " [3.53744836e-03 2.76785381e-02 3.68632287e-01 1.07908566e-02\n",
      "  5.89360833e-01]\n",
      " [3.21190059e-02 6.64945394e-02 6.67403102e-01 4.00314108e-03\n",
      "  2.29980201e-01]]\n",
      "[3 1 0 4 2]\n",
      "第1个为 长笛\n",
      "第2个为 吉他\n",
      "第3个为 钢琴\n",
      "第4个为 手风琴\n",
      "第5个为 小提琴\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.models import load_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.utils import np_utils\n",
    "model_path = f'D:/张斯然文件/musicdate/date/model13.h5'\n",
    "# 载入模型\n",
    "model = load_model(model_path)\n",
    "data_set1=[]\n",
    "for filename in os.listdir(f'D:/张斯然文件/musicdate/date/classes/test/'):\n",
    "    songname = f'D:/张斯然文件/musicdate/date/classes/test/{filename}'\n",
    "    print(songname)\n",
    "    y, sr = librosa.load(songname, mono=True, duration=30)\n",
    "    chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    rmse = librosa.feature.rms(y=y)\n",
    "    spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "    zcr = librosa.feature.zero_crossing_rate(y)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    " \n",
    "    to_append = f'{np.mean(chroma_stft)} {np.mean(rmse)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'    \n",
    " \n",
    "    for e in mfcc:\n",
    "        to_append += f' {np.mean(e)}'\n",
    " \n",
    "    data_set1.append([float(i) for i in to_append.split(\" \")])\n",
    "        \n",
    "scaler = StandardScaler()    \n",
    "X1= scaler.fit_transform(np.array(data_set1, dtype = float))\n",
    "result=model.predict(X1)\n",
    "array=np.argmax(result,axis=1)\n",
    "print(result)\n",
    "print(array)\n",
    "classes=['钢琴','吉他','小提琴','长笛','手风琴']\n",
    "for j in range(0,len(array)):\n",
    "    print(\"第{}个为\".format(j+1),classes[array[j]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11a81f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
